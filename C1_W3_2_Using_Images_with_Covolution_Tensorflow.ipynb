{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> # **Using Images with CNN**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mKVfNK3STpT"
      },
      "source": [
        "## 1) Installing Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30FF-IHXSI4M"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDwfIc_wSnfW"
      },
      "source": [
        "## 2) Importing Required Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urmhbfoiSr04"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras as ks\n",
        "import os\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPmaYyvoxKGQ"
      },
      "source": [
        "## 3) Loading the Image Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1V5R3KxUxN0A",
        "outputId": "7760e989-a354-487c-b931-87e4ba44475a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Maximum pixel value before normalization: 255\n",
            "\n",
            "Shape of training set before reshaping: (60000, 28, 28)\n",
            "\n",
            "Shape of one image before reshaping: (28, 28)\n"
          ]
        }
      ],
      "source": [
        "# Get current working directory\n",
        "current_dir = os.getcwd()\n",
        "\n",
        "# Append data/mnist.npz to the previous path to get the full path\n",
        "data_path = os.path.join(current_dir, \"/content/drive/MyDrive/mnist.npz\")\n",
        "\n",
        "# Get only training set\n",
        "(training_images, training_labels), _ = tf.keras.datasets.mnist.load_data(\n",
        "    path=data_path\n",
        ")\n",
        "\n",
        "print(f\"Maximum pixel value before normalization: {np.max(training_images)}\\n\")\n",
        "print(f\"Shape of training set before reshaping: {training_images.shape}\\n\")\n",
        "print(f\"Shape of one image before reshaping: {training_images[0].shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EE9q3HdlPxkF"
      },
      "source": [
        "## 4) Pre-Processing the Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tiBS1yBZPxK1"
      },
      "outputs": [],
      "source": [
        "def reshape_and_normalize(images):\n",
        "    # Reshape the images to add an extra dimension\n",
        "    # this extra dimension represent the depth of color e.g. for\n",
        "    # rgb it would be 3 but we have a grayscale so it is 1 which\n",
        "    # is not neccessary to define but a good practice\n",
        "    images = images.reshape(images.shape[0], 28, 28, 1)\n",
        "\n",
        "    # Normalize pixel values\n",
        "    images = images / 255.0\n",
        "\n",
        "    return images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qpwAYvdQIv8"
      },
      "source": [
        "## 5) Reshaping the Data:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViAFVwkvQPC2",
        "outputId": "1e9773aa-959a-4657-a893-57e8283bf5a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Maximum pixel value after normalization: 1.0\n",
            "\n",
            "Shape of training set after reshaping: (60000, 28, 28, 1)\n",
            "\n",
            "Shape of one image after reshaping: (28, 28, 1)\n"
          ]
        }
      ],
      "source": [
        "# Reload the images in case you run this cell multiple times\n",
        "(training_images, _), _ = tf.keras.datasets.mnist.load_data(path=data_path)\n",
        "\n",
        "# Apply your function\n",
        "training_images = reshape_and_normalize(training_images)\n",
        "\n",
        "print(f\"Maximum pixel value after normalization: {np.max(training_images)}\\n\")\n",
        "print(f\"Shape of training set after reshaping: {training_images.shape}\\n\")\n",
        "print(f\"Shape of one image after reshaping: {training_images[0].shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OHDVybGxz0B"
      },
      "source": [
        "## 6) Defining Callback\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z44_cjezyCex"
      },
      "outputs": [],
      "source": [
        "class myCallback(ks.callbacks.Callback):\n",
        "    # defining a callback\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if logs.get(\"accuracy\") is not None and logs.get(\"accuracy\") > 0.995:\n",
        "            print(\"\\nReached 95% accuracy so cancelling training!\")\n",
        "\n",
        "            # Stop training once the above condition is met\n",
        "            self.model.stop_training = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7FFCwu9yif_"
      },
      "source": [
        "## 5) Creating the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mwx9vPFyCSj"
      },
      "outputs": [],
      "source": [
        "def convolutional_model():\n",
        "    # Define the Model\n",
        "    model = ks.models.Sequential(\n",
        "        [\n",
        "            # defining convolutional network.\n",
        "            # 64 is the filters: the dimension of the output space (the number of filters in the convolution)\n",
        "            # 3x3 is the kernel size: the height and width of the 2D convolution window\n",
        "            ks.layers.Conv2D(64, (3, 3), activation=\"relu\", input_shape=(28, 28, 1)),\n",
        "            # Downsamples the input along its spatial dimensions\n",
        "            # (height and width) by taking the maximum value over an input window\n",
        "            # (2, 2) is the poolsize: factors by which to downscale (dim1, dim2)\n",
        "            ks.layers.MaxPooling2D(2, 2),\n",
        "            ks.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
        "            ks.layers.MaxPooling2D(2, 2),\n",
        "            ks.layers.Flatten(),\n",
        "            ks.layers.Dense(512, activation=\"relu\"),\n",
        "            ks.layers.Dense(10, activation=\"softmax\"),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(\n",
        "        optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lf5BkGRzy9Tj"
      },
      "source": [
        "## 6) Training the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bmi0rpgIzAMK",
        "outputId": "bb11a17d-5d47-4e5a-eea2-df178c31f973"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "862410\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 18s 9ms/step - loss: 0.1062 - accuracy: 0.9669\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0366 - accuracy: 0.9889\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0249 - accuracy: 0.9924\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0173 - accuracy: 0.9943\n",
            "Epoch 5/10\n",
            "1872/1875 [============================>.] - ETA: 0s - loss: 0.0116 - accuracy: 0.9963\n",
            "Reached 95% accuracy so cancelling training!\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0116 - accuracy: 0.9962\n"
          ]
        }
      ],
      "source": [
        "# Getting the model\n",
        "model = convolutional_model()\n",
        "\n",
        "# Get number of weights\n",
        "model_params = model.count_params()\n",
        "\n",
        "print(model_params)\n",
        "\n",
        "# Unit test to limit the size of the model\n",
        "assert model_params < 1000000, (\n",
        "    f\"Your model has {model_params:,} params. For successful grading, please keep it \"\n",
        "    f\"under 1,000,000 by reducing the number of units in your Conv2D and/or Dense layers.\"\n",
        ")\n",
        "\n",
        "# Instantiate the callback class\n",
        "callbacks = myCallback()\n",
        "\n",
        "# Train your model (this can take up to 5 minutes)\n",
        "history = model.fit(training_images, training_labels, epochs=10, callbacks=[callbacks])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Efz2y6xZzFdJ"
      },
      "source": [
        "## 7) Getting Model Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZIr42xizFBh",
        "outputId": "8d199efa-e604-47a4-d406-efd2bb0b2013"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 26, 26, 64)        640       \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 13, 13, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 11, 11, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 5, 5, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 1600)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 512)               819712    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 862410 (3.29 MB)\n",
            "Trainable params: 862410 (3.29 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
