{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **1) Installing Dependencies**"
      ],
      "metadata": {
        "id": "8mKVfNK3STpT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30FF-IHXSI4M"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2) Importing Required Libraries**"
      ],
      "metadata": {
        "id": "lDwfIc_wSnfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras as ks\n",
        "import os"
      ],
      "metadata": {
        "id": "urmhbfoiSr04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3) Loading the Image Data**"
      ],
      "metadata": {
        "id": "jPmaYyvoxKGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get current working directory\n",
        "current_dir = os.getcwd()\n",
        "\n",
        "# Append data/mnist.npz to the previous path to get the full path\n",
        "data_path = os.path.join(current_dir, \"/content/drive/MyDrive/mnist.npz\")\n",
        "\n",
        "# Discard test set\n",
        "(x_train, y_train), _ = tf.keras.datasets.mnist.load_data(path=data_path)\n",
        "\n",
        "# Normalize pixel values\n",
        "x_train = x_train / 255.0\n",
        "\n",
        "print(x_train[0][5])\n",
        "\n",
        "data_shape = x_train.shape\n",
        "\n",
        "print(f\"\\nThere are {data_shape[0]} examples with shape ({data_shape[1]}, {data_shape[2]})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1V5R3KxUxN0A",
        "outputId": "19259544-9cee-430a-bc5c-62e70e58ca67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.01176471 0.07058824 0.07058824 0.07058824 0.49411765 0.53333333\n",
            " 0.68627451 0.10196078 0.65098039 1.         0.96862745 0.49803922\n",
            " 0.         0.         0.         0.        ]\n",
            "\n",
            "There are 60000 examples with shape (28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4) Defining Callback**"
      ],
      "metadata": {
        "id": "6OHDVybGxz0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inherit our class from callback class\n",
        "class myCallback(ks.callbacks.Callback):\n",
        "\n",
        "  # defining a callback\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if logs.get('accuracy') is not None and logs.get('accuracy') > 0.99:\n",
        "        print(\"\\nReached 99% accuracy so cancelling training!\")\n",
        "\n",
        "        # Stop training once the above condition is met\n",
        "        self.model.stop_training = True"
      ],
      "metadata": {
        "id": "Z44_cjezyCex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5) Creating the Model**"
      ],
      "metadata": {
        "id": "n7FFCwu9yif_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_mnist(x_train, y_train):\n",
        "\n",
        "  # Instantiate the callback class\n",
        "  callbacks = myCallback()\n",
        "\n",
        "  # Define the model\n",
        "  model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "      tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "  ])\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(optimizer='adam',\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  # Fit the model for 10 epochs adding the callbacks\n",
        "  # and save the training history\n",
        "  history = model.fit(x_train, y_train, epochs=10, callbacks=[callbacks])\n",
        "\n",
        "  return [history, model]"
      ],
      "metadata": {
        "id": "3mwx9vPFyCSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6) Training the Model**"
      ],
      "metadata": {
        "id": "lf5BkGRzy9Tj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[hist, model] = train_mnist(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bmi0rpgIzAMK",
        "outputId": "c5ba4e54-4478-46a6-b9ed-5605731468d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1986 - accuracy: 0.9412\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0777 - accuracy: 0.9764\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0517 - accuracy: 0.9840\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0375 - accuracy: 0.9878\n",
            "Epoch 5/10\n",
            "1862/1875 [============================>.] - ETA: 0s - loss: 0.0270 - accuracy: 0.9911\n",
            "Reached 99% accuracy so cancelling training!\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0270 - accuracy: 0.9911\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7) Getting Model Summary**"
      ],
      "metadata": {
        "id": "Efz2y6xZzFdJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZIr42xizFBh",
        "outputId": "5db79c41-3fc3-4df7-f59c-4cd06a4fc516"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_5 (Flatten)         (32, 784)                 0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (32, 512)                 401920    \n",
            "                                                                 \n",
            " dense_11 (Dense)            (32, 10)                  5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 407050 (1.55 MB)\n",
            "Trainable params: 407050 (1.55 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}